{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Final Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DQ checks for Final Task. Source data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__DataFrame that contains test results__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table = pd.DataFrame(columns = ['Table','DQ check','Column','Status','Bad Data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Function for check completeness by not null value__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Completeness_by_not_null(path,list_of_columns):\n",
    "    data = pd.read_csv(path)\n",
    "    result_row = []\n",
    "    a = []\n",
    "    col_count = len(list_of_columns)\n",
    "    for i in range (col_count):\n",
    "        a.append(data[list_of_columns[i]].isnull().sum())\n",
    "        if a[i] > 0:\n",
    "            status = 'Failed'\n",
    "            bad_data = f'In the column {list_of_columns[i]} exist {a[i]} rows with Null value.'\n",
    "        else:\n",
    "            status = 'Passed'\n",
    "            bad_data = f'In the column  {list_of_columns[i]} no null value.'\n",
    "        result_row.append([path.split('.csv')[0].title(),'Completeness',list_of_columns[i],status,bad_data])\n",
    "    res = pd.DataFrame(result_row)\n",
    "    res.columns = ['Table','DQ check','Column','Status','Bad Data']\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TC.1 Carrier: completeness by not nullable fields__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Table      DQ check  \\\n",
      "0  Gs://Iskldl04-Dqelearn-Local-Bucket/Source/Car...  Completeness   \n",
      "1  Gs://Iskldl04-Dqelearn-Local-Bucket/Source/Car...  Completeness   \n",
      "\n",
      "        Column  Status                                           Bad Data  \n",
      "0         Code  Failed   In the column Code exist 5 rows with Null value.  \n",
      "1  Description  Failed  In the column Description exist 3 rows with Nu...  \n"
     ]
    }
   ],
   "source": [
    "list_of_columns_carriers = ['Code','Description']\n",
    "path_carriers = 'gs://iskldl04-dqelearn-local-bucket/source/carriers.csv'\n",
    "#'source_data/carriers.csv' - for local run\n",
    "result_carriers = Completeness_by_not_null(path_carriers,list_of_columns_carriers)\n",
    "print(result_carriers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Function for check Uniqueness by PK__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Uniqueness_by_PK(path,list_of_columns):\n",
    "    data = pd.read_csv(path)\n",
    "    result_row = []\n",
    "    a = []\n",
    "    col = []\n",
    "    col_count = len(list_of_columns)\n",
    "    for i in range (col_count):\n",
    "        a.append(data[list_of_columns[i]].value_counts())\n",
    "    res_count = pd.DataFrame(a)\n",
    "    len_col = len(res_count.columns)\n",
    "    for i in range(len(res_count)):\n",
    "        for j in res_count.columns:\n",
    "            col.append(j)\n",
    "            if res_count[j][i] > 1:\n",
    "                status = 'Failed'\n",
    "                bad_data = f'Exist duplicates fro value {j}. Duplicates count is {res_count[j][i]}.'\n",
    "            else:\n",
    "                continue\n",
    "            result_row.append([path.split('.csv')[0].title(),'Uniqueness', res_count.index[i],status,bad_data])\n",
    "    res = pd.DataFrame(result_row)\n",
    "    res.columns = ['Table','DQ check','Column','Status','Bad Data']\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TC2. Airports: Uniqueness by PK__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Table    DQ check Column  \\\n",
      "0  Gs://Iskldl04-Dqelearn-Local-Bucket/Source/Air...  Uniqueness   iata   \n",
      "1  Gs://Iskldl04-Dqelearn-Local-Bucket/Source/Air...  Uniqueness   iata   \n",
      "2  Gs://Iskldl04-Dqelearn-Local-Bucket/Source/Air...  Uniqueness   iata   \n",
      "3  Gs://Iskldl04-Dqelearn-Local-Bucket/Source/Air...  Uniqueness   iata   \n",
      "4  Gs://Iskldl04-Dqelearn-Local-Bucket/Source/Air...  Uniqueness   iata   \n",
      "5  Gs://Iskldl04-Dqelearn-Local-Bucket/Source/Air...  Uniqueness   iata   \n",
      "\n",
      "   Status                                           Bad Data  \n",
      "0  Failed  Exist duplicates fro value 00M. Duplicates cou...  \n",
      "1  Failed  Exist duplicates fro value Z13. Duplicates cou...  \n",
      "2  Failed  Exist duplicates fro value Z08. Duplicates cou...  \n",
      "3  Failed  Exist duplicates fro value Z09. Duplicates cou...  \n",
      "4  Failed  Exist duplicates fro value 00R. Duplicates cou...  \n",
      "5  Failed  Exist duplicates fro value 00V. Duplicates cou...  \n"
     ]
    }
   ],
   "source": [
    "path_airports = 'gs://iskldl04-dqelearn-local-bucket/source/airports.csv'\n",
    "#'source_data/airports.csv' - for local run\n",
    "list_of_columns_airports = ['iata']\n",
    "#list_of_columns_airports = ['iata','city']\n",
    "result_airports = Uniqueness_by_PK(path_airports,list_of_columns_airports)\n",
    "print(result_airports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Function for  Consistency check for Foreign Key__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Consistency_by_FK(path_pk,col_pk,path_fk,col_fk):\n",
    "    car_code = pd.read_csv(path_pk)\n",
    "    air_uniqcar = pd.read_csv(path_fk)\n",
    "    car_code_array = car_code[col_pk].to_numpy()\n",
    "    air_uniqcar_array = air_uniqcar[col_fk].drop_duplicates().to_numpy()\n",
    "    result_row = []\n",
    "    for i in range(len(air_uniqcar_array)):\n",
    "        if air_uniqcar_array[i] not in car_code_array:\n",
    "            status = 'Failed'\n",
    "            col = col_fk[0]\n",
    "            colpk = col_pk[0]\n",
    "            value = air_uniqcar_array[i][0]\n",
    "            bad_data = f'In the column {col} exist value {value} not from {colpk}'\n",
    "            result_row.append([path_fk.split('.csv')[0].title(),'Consistency by FK', col, status,bad_data])\n",
    "        else:\n",
    "            continue\n",
    "    res = pd.DataFrame(result_row)\n",
    "    res.columns = ['Table','DQ check','Column','Status','Bad Data']\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TC3. Flights: Consistency check for UniqueCarrier__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Table           DQ check  \\\n",
      "0  Gs://Iskldl04-Dqelearn-Local-Bucket/Source/Fli...  Consistency by FK   \n",
      "1  Gs://Iskldl04-Dqelearn-Local-Bucket/Source/Fli...  Consistency by FK   \n",
      "2  Gs://Iskldl04-Dqelearn-Local-Bucket/Source/Fli...  Consistency by FK   \n",
      "\n",
      "          Column  Status                                           Bad Data  \n",
      "0  UniqueCarrier  Failed  In the column UniqueCarrier exist value AXX no...  \n",
      "1  UniqueCarrier  Failed  In the column UniqueCarrier exist value 1B9 no...  \n",
      "2  UniqueCarrier  Failed  In the column UniqueCarrier exist value nan no...  \n"
     ]
    }
   ],
   "source": [
    "path_flights = 'gs://iskldl04-dqelearn-local-bucket/source/flights.csv'\n",
    "#'source_data/flights.csv' - for local run\n",
    "column_flights_fk = ['UniqueCarrier']\n",
    "column_carriers_pk = ['Code']\n",
    "\n",
    "result_flights_fk = Consistency_by_FK(path_carriers,column_carriers_pk,path_flights,column_flights_fk)\n",
    "print(result_flights_fk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Function for  Flights: Consistency check for Time Delay____\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Consistency_TimeDelay(path,time_col_agg, agg_1,agg_2):\n",
    "    data = pd.read_csv(path)\n",
    "    result_row = []\n",
    "    data['difference'] = data[agg_1[0]] - data[agg_2[0]]\n",
    "    for i in range(len(data)):\n",
    "        if data[time_col_agg[0]][i] != data['difference'][i]:\n",
    "            aggres = data['difference']\n",
    "            status = 'Failed'\n",
    "            bad_data = f'In the row {i} data do not match computed calue based on other attributes. {data[time_col_agg[0]][i]} = {time_col_agg[0]} != {agg_1[0]} - {agg_2[0]} = {aggres[i]}'\n",
    "            result_row.append([path.split('.csv')[0].title(),'Consistency DepDelay', time_col_agg[0], status, bad_data])\n",
    "        else:\n",
    "            continue\n",
    "    res = pd.DataFrame(result_row)\n",
    "    res.columns = ['Table','DQ check','Column','Status','Bad Data']\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TC4. Flights: Consistency check for DepDelay__\n",
    "\n",
    "Calculated column: DepTime - CRSDepTime (mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Table              DQ check  \\\n",
      "0    Gs://Iskldl04-Dqelearn-Local-Bucket/Source/Fli...  Consistency DepDelay   \n",
      "1    Gs://Iskldl04-Dqelearn-Local-Bucket/Source/Fli...  Consistency DepDelay   \n",
      "2    Gs://Iskldl04-Dqelearn-Local-Bucket/Source/Fli...  Consistency DepDelay   \n",
      "3    Gs://Iskldl04-Dqelearn-Local-Bucket/Source/Fli...  Consistency DepDelay   \n",
      "4    Gs://Iskldl04-Dqelearn-Local-Bucket/Source/Fli...  Consistency DepDelay   \n",
      "..                                                 ...                   ...   \n",
      "202  Gs://Iskldl04-Dqelearn-Local-Bucket/Source/Fli...  Consistency DepDelay   \n",
      "203  Gs://Iskldl04-Dqelearn-Local-Bucket/Source/Fli...  Consistency DepDelay   \n",
      "204  Gs://Iskldl04-Dqelearn-Local-Bucket/Source/Fli...  Consistency DepDelay   \n",
      "205  Gs://Iskldl04-Dqelearn-Local-Bucket/Source/Fli...  Consistency DepDelay   \n",
      "206  Gs://Iskldl04-Dqelearn-Local-Bucket/Source/Fli...  Consistency DepDelay   \n",
      "\n",
      "       Column  Status                                           Bad Data  \n",
      "0    DepDelay  Failed  In the row 0 data do not match computed calue ...  \n",
      "1    DepDelay  Failed  In the row 1 data do not match computed calue ...  \n",
      "2    DepDelay  Failed  In the row 2 data do not match computed calue ...  \n",
      "3    DepDelay  Failed  In the row 5 data do not match computed calue ...  \n",
      "4    DepDelay  Failed  In the row 15 data do not match computed calue...  \n",
      "..        ...     ...                                                ...  \n",
      "202  DepDelay  Failed  In the row 518 data do not match computed calu...  \n",
      "203  DepDelay  Failed  In the row 519 data do not match computed calu...  \n",
      "204  DepDelay  Failed  In the row 520 data do not match computed calu...  \n",
      "205  DepDelay  Failed  In the row 521 data do not match computed calu...  \n",
      "206  DepDelay  Failed  In the row 528 data do not match computed calu...  \n",
      "\n",
      "[207 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "col = ['DepDelay']\n",
    "col1 = ['DepTime']\n",
    "col2 = ['CRSDepTime']\n",
    "result_flight_time = Consistency_TimeDelay(path_flights,col,col1,col2)\n",
    "print(result_flight_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Saving test results in the csv file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test functions on another data\n",
    "#resair = ['city','iata']\n",
    "#res_air = Completeness_by_not_null(path_airports,resair)\n",
    "#list_of_columns_car = ['Code','Description']\n",
    "#result_car = Uniqueness_by_PK(path_carriers,list_of_columns_car)\n",
    "#column_flights_fk_2 = ['Origin']\n",
    "#column_air_pk = ['iata']\n",
    "#result_flights_fk_2 = Consistency_by_FK(path_airports,column_air_pk,path_flights,column_flights_fk_2)\n",
    "\n",
    "#result = pd.concat([result_table,result_carriers, res_air,  result_airports,result_car, result_flights_fk,result_flights_fk_2], ignore_index=True)\n",
    "\n",
    "\n",
    "result = pd.concat([result_table,result_carriers, result_airports, result_flights_fk, result_flight_time], ignore_index=True)\n",
    "result.index += 1\n",
    "\n",
    "result.to_csv('Test_result_Source.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Table              DQ check  \\\n",
      "1    Gs://Iskldl04-Dqelearn-Local-Bucket/Source/Car...          Completeness   \n",
      "2    Gs://Iskldl04-Dqelearn-Local-Bucket/Source/Car...          Completeness   \n",
      "3    Gs://Iskldl04-Dqelearn-Local-Bucket/Source/Air...            Uniqueness   \n",
      "4    Gs://Iskldl04-Dqelearn-Local-Bucket/Source/Air...            Uniqueness   \n",
      "5    Gs://Iskldl04-Dqelearn-Local-Bucket/Source/Air...            Uniqueness   \n",
      "..                                                 ...                   ...   \n",
      "214  Gs://Iskldl04-Dqelearn-Local-Bucket/Source/Fli...  Consistency DepDelay   \n",
      "215  Gs://Iskldl04-Dqelearn-Local-Bucket/Source/Fli...  Consistency DepDelay   \n",
      "216  Gs://Iskldl04-Dqelearn-Local-Bucket/Source/Fli...  Consistency DepDelay   \n",
      "217  Gs://Iskldl04-Dqelearn-Local-Bucket/Source/Fli...  Consistency DepDelay   \n",
      "218  Gs://Iskldl04-Dqelearn-Local-Bucket/Source/Fli...  Consistency DepDelay   \n",
      "\n",
      "          Column  Status                                           Bad Data  \n",
      "1           Code  Failed   In the column Code exist 5 rows with Null value.  \n",
      "2    Description  Failed  In the column Description exist 3 rows with Nu...  \n",
      "3           iata  Failed  Exist duplicates fro value 00M. Duplicates cou...  \n",
      "4           iata  Failed  Exist duplicates fro value Z13. Duplicates cou...  \n",
      "5           iata  Failed  Exist duplicates fro value Z08. Duplicates cou...  \n",
      "..           ...     ...                                                ...  \n",
      "214     DepDelay  Failed  In the row 518 data do not match computed calu...  \n",
      "215     DepDelay  Failed  In the row 519 data do not match computed calu...  \n",
      "216     DepDelay  Failed  In the row 520 data do not match computed calu...  \n",
      "217     DepDelay  Failed  In the row 521 data do not match computed calu...  \n",
      "218     DepDelay  Failed  In the row 528 data do not match computed calu...  \n",
      "\n",
      "[218 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Local PySpark (Python-3.7.9 / Spark-3.0.1 )",
   "language": "python",
   "name": "py3spark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
