{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Final Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DQ checks for Final Task\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__DataFrame that contains test results__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_table = pd.DataFrame(columns = ['Table','DQ check','Column','Status','Bad Data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Function for check completeness by not null value__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Completeness_by_not_null(path,list_of_columns):\n",
    "    data = pd.read_csv(path)\n",
    "    result_row = []\n",
    "    a = []\n",
    "    col_count = len(list_of_columns)\n",
    "    for i in range (col_count):\n",
    "        a.append(data[list_of_columns[i]].isnull().sum())\n",
    "        if a[i] > 0:\n",
    "            status = 'Failed'\n",
    "            bad_data = f'In the column {list_of_columns[i]} exist {a[i]} rows with Null value.'\n",
    "        else:\n",
    "            status = 'Passed'\n",
    "            bad_data = f'In the column  {list_of_columns[i]} no null value.'\n",
    "        result_row.append([path.split('.csv')[0].title(),'Completeness',list_of_columns[i],status,bad_data])\n",
    "    res = pd.DataFrame(result_row)\n",
    "    res.columns = ['Table','DQ check','Column','Status','Bad Data']\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TC.1 Carrier: completeness by not nullable fields__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_columns_carriers = ['Code','Description']\n",
    "path_carriers = 'carriers.csv'\n",
    "result_carriers = Completeness_by_not_null(path_carriers,list_of_columns_carriers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Function for check Uniqueness by PK__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Uniqueness_by_PK(path,list_of_columns):\n",
    "    data = pd.read_csv(path)\n",
    "    result_row = []\n",
    "    a = []\n",
    "    col = []\n",
    "    col_count = len(list_of_columns)\n",
    "    for i in range (col_count):\n",
    "        a.append(data[list_of_columns[i]].value_counts())\n",
    "    res_count = pd.DataFrame(a)\n",
    "    len_col = len(res_count.columns)\n",
    "    for i in range(len(res_count)):\n",
    "        for j in res_count.columns:\n",
    "            col.append(j)\n",
    "            if res_count[j][i] > 1:\n",
    "                status = 'Failed'\n",
    "                bad_data = f'Exist duplicates fro value {j}. Duplicates count is {res_count[j][i]}.'\n",
    "            else:\n",
    "                continue\n",
    "            result_row.append([path.split('.csv')[0].title(),'Uniqueness', res_count.index[i],status,bad_data])\n",
    "    res = pd.DataFrame(result_row)\n",
    "    res.columns = ['Table','DQ check','Column','Status','Bad Data']\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TC2. Airports: Uniqueness by PK__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_airports = 'airports.csv'\n",
    "list_of_columns_airports = ['iata']\n",
    "#list_of_columns_airports = ['iata','city']\n",
    "result_airports = Uniqueness_by_PK(path_airports,list_of_columns_airports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Function for  Consistency check for Foreign Key__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Consistency_by_FK(path_pk,col_pk,path_fk,col_fk):\n",
    "    car_code = pd.read_csv(path_pk)\n",
    "    air_uniqcar = pd.read_csv(path_fk)\n",
    "    car_code_array = car_code[col_pk].to_numpy()\n",
    "    air_uniqcar_array = air_uniqcar[col_fk].drop_duplicates().to_numpy()\n",
    "    result_row = []\n",
    "    for i in range(len(air_uniqcar_array)):\n",
    "        if air_uniqcar_array[i] not in car_code_array:\n",
    "            status = 'Failed'\n",
    "            col = col_fk[0]\n",
    "            colpk = col_pk[0]\n",
    "            value = air_uniqcar_array[i][0]\n",
    "            bad_data = f'In the column {col} exist value {value} not from {colpk}'\n",
    "            result_row.append([path_fk.split('.csv')[0].title(),'Consistency by FK', col, status,bad_data])\n",
    "        else:\n",
    "            continue\n",
    "    res = pd.DataFrame(result_row)\n",
    "    res.columns = ['Table','DQ check','Column','Status','Bad Data']\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TC3. Flights: Consistency check for UniqueCarrier__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_flights = 'flights.csv'\n",
    "column_flights_fk = ['UniqueCarrier']\n",
    "column_carriers_pk = ['Code']\n",
    "\n",
    "result_flights_fk = Consistency_by_FK(path_carriers,column_carriers_pk,path_flights,column_flights_fk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Function for  Flights: Consistency check for DepDelay__\n",
    "\n",
    "Calculated column: DepTime - CRSDepTime (mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Consistency_TimeDelay(path,time_col_agg, agg_1,agg_2):\n",
    "    data = pd.read_csv(path)\n",
    "    result_row = []\n",
    "    data['difference'] = data[agg_1[0]] - data[agg_2[0]]\n",
    "    for i in range(len(data)):\n",
    "        if data[time_col_agg[0]][i] != data['difference'][i]:\n",
    "            aggres = data['difference']\n",
    "            status = 'Failed'\n",
    "            bad_data = f'In the row {i} data do not match computed calue based on other attributes. {data[time_col_agg[0]][i]} = {time_col_agg[0]} != {agg_1[0]} - {agg_2[0]} = {aggres[i]}'\n",
    "            result_row.append([path.split('.csv')[0].title(),'Consistency DepDelay', time_col_agg[0], status, bad_data])\n",
    "        else:\n",
    "            continue\n",
    "    res = pd.DataFrame(result_row)\n",
    "    res.columns = ['Table','DQ check','Column','Status','Bad Data']\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TC4. Flights: Consistency check for DepDelay__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['DepDelay']\n",
    "col1 = ['DepTime']\n",
    "col2 = ['CRSDepTime']\n",
    "result_flight_time = Consistency_TimeDelay(path_flights,col,col1,col2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Saving test results in the csv file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test functions on another data\n",
    "#resair = ['city','iata']\n",
    "#res_air = Completeness_by_not_null(path_airports,resair)\n",
    "#list_of_columns_car = ['Code','Description']\n",
    "#result_car = Uniqueness_by_PK(path_carriers,list_of_columns_car)\n",
    "#column_flights_fk_2 = ['Origin']\n",
    "#column_air_pk = ['iata']\n",
    "#result_flights_fk_2 = Consistency_by_FK(path_airports,column_air_pk,path_flights,column_flights_fk_2)\n",
    "\n",
    "#result = pd.concat([result_table,result_carriers, res_air,  result_airports,result_car, result_flights_fk,result_flights_fk_2], ignore_index=True)\n",
    "\n",
    "\n",
    "result = pd.concat([result_table,result_carriers, result_airports, result_flights_fk, result_flight_time], ignore_index=True)\n",
    "result.index += 1\n",
    "\n",
    "result.to_csv('Test_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
