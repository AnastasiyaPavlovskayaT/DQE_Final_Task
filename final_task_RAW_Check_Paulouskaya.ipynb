{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbb02841",
   "metadata": {},
   "source": [
    "__DQ checks for Final Task. RAW data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "422539e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#DataFrame that contains test results\n",
    "result_table = pd.DataFrame(columns = ['Table','DQ check','Column','Status','Bad Data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c565ec",
   "metadata": {},
   "source": [
    "\n",
    "__Function for check completeness by not null value__\n",
    "\n",
    "__TC.1 Carrier: completeness by not nullable fields__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f12cf610",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Table    DQ check Column  \\\n",
      "0  Gs://Iskldl04-Dqelearn-Local-Bucket/Raw/Airports  Uniqueness   iata   \n",
      "1  Gs://Iskldl04-Dqelearn-Local-Bucket/Raw/Airports  Uniqueness   iata   \n",
      "2  Gs://Iskldl04-Dqelearn-Local-Bucket/Raw/Airports  Uniqueness   iata   \n",
      "3  Gs://Iskldl04-Dqelearn-Local-Bucket/Raw/Airports  Uniqueness   iata   \n",
      "4  Gs://Iskldl04-Dqelearn-Local-Bucket/Raw/Airports  Uniqueness   iata   \n",
      "5  Gs://Iskldl04-Dqelearn-Local-Bucket/Raw/Airports  Uniqueness   iata   \n",
      "6  Gs://Iskldl04-Dqelearn-Local-Bucket/Raw/Airports  Uniqueness   iata   \n",
      "\n",
      "   Status                                           Bad Data  \n",
      "0  Failed  Exist duplicates fro value 00V. Duplicates cou...  \n",
      "1  Failed  Exist duplicates fro value 00R. Duplicates cou...  \n",
      "2  Failed  Exist duplicates fro value . Duplicates count ...  \n",
      "3  Failed  Exist duplicates fro value Z13. Duplicates cou...  \n",
      "4  Failed  Exist duplicates fro value Z09. Duplicates cou...  \n",
      "5  Failed  Exist duplicates fro value Z08. Duplicates cou...  \n",
      "6  Failed  Exist duplicates fro value 00M. Duplicates cou...  \n"
     ]
    }
   ],
   "source": [
    "def Uniqueness_by_PK(path,list_of_columns):\n",
    "    data = sqlContext.read.parquet(path).toPandas()\n",
    "    result_row = []\n",
    "    a = []\n",
    "    col = []\n",
    "    col_count = len(list_of_columns)\n",
    "    for i in range (col_count):\n",
    "        a.append(data[list_of_columns[i]].value_counts())\n",
    "    res_count = pd.DataFrame(a)\n",
    "    len_col = len(res_count.columns)\n",
    "    for i in range(len(res_count)):\n",
    "        for j in res_count.columns:\n",
    "            col.append(j)\n",
    "            if res_count[j][i] > 1:\n",
    "                status = 'Failed'\n",
    "                bad_data = f'Exist duplicates fro value {j}. Duplicates count is {res_count[j][i]}.'\n",
    "            else:\n",
    "                continue\n",
    "            result_row.append([path.split('.csv')[0].title(),'Uniqueness', res_count.index[i],status,bad_data])\n",
    "    res = pd.DataFrame(result_row)\n",
    "    res.columns = ['Table','DQ check','Column','Status','Bad Data']\n",
    "    return res\n",
    "\n",
    "path_airports = pAirports='gs://iskldl04-dqelearn-local-bucket/raw/airports'\n",
    "list_of_columns_airports = ['iata']\n",
    "#list_of_columns_airports = ['iata','city']\n",
    "result_airports = Uniqueness_by_PK(path_airports,list_of_columns_airports)\n",
    "print(result_airports)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e30e1fc",
   "metadata": {},
   "source": [
    "__Function for check Uniqueness by PK__ \n",
    "\n",
    "__TC2. Airports: Uniqueness by PK__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae25c6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Table      DQ check  \\\n",
      "0  Gs://Iskldl04-Dqelearn-Local-Bucket/Raw/Carriers  Completeness   \n",
      "1  Gs://Iskldl04-Dqelearn-Local-Bucket/Raw/Carriers  Completeness   \n",
      "\n",
      "        Column  Status                                   Bad Data  \n",
      "0         code  Passed         In the column  code no null value.  \n",
      "1  description  Passed  In the column  description no null value.  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def Completeness_by_not_null(path,list_of_columns):\n",
    "    data = sqlContext.read.parquet(path).toPandas()\n",
    "    result_row = []\n",
    "    a = []\n",
    "    col_count = len(list_of_columns)\n",
    "    for i in range (col_count):\n",
    "        a.append(data[list_of_columns[i]].isnull().sum())\n",
    "        if a[i] > 0:\n",
    "            status = 'Failed'\n",
    "            bad_data = f'In the column {list_of_columns[i]} exist {a[i]} rows with Null value.'\n",
    "        else:\n",
    "            status = 'Passed'\n",
    "            bad_data = f'In the column  {list_of_columns[i]} no null value.'\n",
    "        result_row.append([path.split('.csv')[0].title(),'Completeness',list_of_columns[i],status,bad_data])\n",
    "    res = pd.DataFrame(result_row)\n",
    "    res.columns = ['Table','DQ check','Column','Status','Bad Data']\n",
    "    return res\n",
    "\n",
    "list_of_columns_carriers = ['code','description']\n",
    "path_carriers = 'gs://iskldl04-dqelearn-local-bucket/raw/carriers'\n",
    "result_carriers = Completeness_by_not_null(path_carriers,list_of_columns_carriers)\n",
    "print(result_carriers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f04699",
   "metadata": {},
   "source": [
    "__Function for  Consistency check for Foreign Key__\n",
    "\n",
    "__TC3. Flights: Consistency check for UniqueCarrier__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e79f834",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/12 18:15:03 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Table           DQ check  \\\n",
      "0  Gs://Iskldl04-Dqelearn-Local-Bucket/Raw/ Flights  Consistency by FK   \n",
      "1  Gs://Iskldl04-Dqelearn-Local-Bucket/Raw/ Flights  Consistency by FK   \n",
      "\n",
      "          Column  Status                                           Bad Data  \n",
      "0  UniqueCarrier  Failed  In the column UniqueCarrier exist value AXX no...  \n",
      "1  UniqueCarrier  Failed  In the column UniqueCarrier exist value 1B9 no...  \n"
     ]
    }
   ],
   "source": [
    "def Consistency_by_FK(path_pk,col_pk,path_fk,col_fk):\n",
    "    car_code = sqlContext.read.parquet(path_pk).toPandas()\n",
    "    air_uniqcar =  sqlContext.read.parquet(path_fk).toPandas() \n",
    "    car_code_array = car_code[col_pk].to_numpy()\n",
    "    air_uniqcar_array = air_uniqcar[col_fk].drop_duplicates().to_numpy()\n",
    "    result_row = []\n",
    "    for i in range(len(air_uniqcar_array)):\n",
    "        if air_uniqcar_array[i] not in car_code_array:\n",
    "            status = 'Failed'\n",
    "            col = col_fk[0]\n",
    "            colpk = col_pk[0]\n",
    "            value = air_uniqcar_array[i][0]\n",
    "            bad_data = f'In the column {col} exist value {value} not from {colpk}'\n",
    "            result_row.append([path_fk.split('.csv')[0].title(),'Consistency by FK', col, status,bad_data])\n",
    "        else:\n",
    "            continue\n",
    "    res = pd.DataFrame(result_row)\n",
    "    res.columns = ['Table','DQ check','Column','Status','Bad Data']\n",
    "    return res\n",
    "\n",
    "path_flights = 'gs://iskldl04-dqelearn-local-bucket/raw/ flights'\n",
    "column_flights_fk = ['UniqueCarrier']\n",
    "column_carriers_pk = ['code']\n",
    "\n",
    "result_flights_fk = Consistency_by_FK(path_carriers,column_carriers_pk,path_flights,column_flights_fk)\n",
    "print(result_flights_fk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71dd074",
   "metadata": {},
   "source": [
    "__Function for  Flights: Consistency check for Time Delay__\n",
    "\n",
    "__TC4. Flights: Consistency check for DepDelay__    \n",
    "Calculated column: DepTime - CRSDepTime (mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46473e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Table              DQ check  \\\n",
      "0    Gs://Iskldl04-Dqelearn-Local-Bucket/Raw/ Flights  Consistency DepDelay   \n",
      "1    Gs://Iskldl04-Dqelearn-Local-Bucket/Raw/ Flights  Consistency DepDelay   \n",
      "2    Gs://Iskldl04-Dqelearn-Local-Bucket/Raw/ Flights  Consistency DepDelay   \n",
      "3    Gs://Iskldl04-Dqelearn-Local-Bucket/Raw/ Flights  Consistency DepDelay   \n",
      "4    Gs://Iskldl04-Dqelearn-Local-Bucket/Raw/ Flights  Consistency DepDelay   \n",
      "..                                                ...                   ...   \n",
      "532  Gs://Iskldl04-Dqelearn-Local-Bucket/Raw/ Flights  Consistency DepDelay   \n",
      "533  Gs://Iskldl04-Dqelearn-Local-Bucket/Raw/ Flights  Consistency DepDelay   \n",
      "534  Gs://Iskldl04-Dqelearn-Local-Bucket/Raw/ Flights  Consistency DepDelay   \n",
      "535  Gs://Iskldl04-Dqelearn-Local-Bucket/Raw/ Flights  Consistency DepDelay   \n",
      "536  Gs://Iskldl04-Dqelearn-Local-Bucket/Raw/ Flights  Consistency DepDelay   \n",
      "\n",
      "       Column  Status                                           Bad Data  \n",
      "0    DepDelay  Failed  In the row 0 data do not match computed calue ...  \n",
      "1    DepDelay  Failed  In the row 1 data do not match computed calue ...  \n",
      "2    DepDelay  Failed  In the row 2 data do not match computed calue ...  \n",
      "3    DepDelay  Failed  In the row 3 data do not match computed calue ...  \n",
      "4    DepDelay  Failed  In the row 4 data do not match computed calue ...  \n",
      "..        ...     ...                                                ...  \n",
      "532  DepDelay  Failed  In the row 532 data do not match computed calu...  \n",
      "533  DepDelay  Failed  In the row 533 data do not match computed calu...  \n",
      "534  DepDelay  Failed  In the row 534 data do not match computed calu...  \n",
      "535  DepDelay  Failed  In the row 535 data do not match computed calu...  \n",
      "536  DepDelay  Failed  In the row 536 data do not match computed calu...  \n",
      "\n",
      "[537 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "def Consistency_TimeDelay(path,time_col_agg, agg_1,agg_2):\n",
    "    data = sqlContext.read.parquet(path).toPandas()\n",
    "    result_row = []\n",
    "    data['difference'] = data[agg_1[0]].replace(['NA',''],[0,0]).astype(int) - data[agg_2[0]].replace(['NA',''],[0,0]).astype(int)\n",
    "    for i in range(len(data)):\n",
    "        if data[time_col_agg[0]][i] != data['difference'][i]:\n",
    "            aggres = data['difference']\n",
    "            status = 'Failed'\n",
    "            bad_data = f'In the row {i} data do not match computed calue based on other attributes. {data[time_col_agg[0]][i]} = {time_col_agg[0]} != {agg_1[0]} - {agg_2[0]} = {aggres[i]}'\n",
    "            result_row.append([path.split('.csv')[0].title(),'Consistency DepDelay', time_col_agg[0], status, bad_data])\n",
    "        else:\n",
    "            continue\n",
    "    res = pd.DataFrame(result_row)\n",
    "    res.columns = ['Table','DQ check','Column','Status','Bad Data']\n",
    "    return res\n",
    "\n",
    "col = ['DepDelay']\n",
    "col1 = ['DepTime']\n",
    "col2 = ['CRSDepTime']\n",
    "result_flight_time = Consistency_TimeDelay(path_flights,col,col1,col2)\n",
    "print(result_flight_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f626ae",
   "metadata": {},
   "source": [
    "__Saving test results in the csv file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b16d3418",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([result_table,result_carriers, result_airports, result_flights_fk, result_flight_time], ignore_index=True)\n",
    "result.index += 1\n",
    "\n",
    "result.to_csv('Test_result_Raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b33b303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Local PySpark (Python-3.7.9 / Spark-3.0.1 )",
   "language": "python",
   "name": "py3spark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
